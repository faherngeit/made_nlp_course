{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eulvfJWl7ueY"
   },
   "source": [
    "## Homework 02: Unsupervised embedding-based MT\n",
    "*Note: this homework is based on open materials from yandexdataschool [NLP course](https://github.com/yandexdataschool/nlp_course/). Feel free to check this awesome course if you wish to dig deeper.*\n",
    "\n",
    "*Refined by [Nikolay Karpachev](https://www.linkedin.com/in/nikolay-karpachev-b0146a104/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fV4rIjxa7uei"
   },
   "source": [
    "**In this homework** **<font color='red'>YOU</font>** will make machine translation system without using parallel corpora, alignment, attention, 100500 depth super-cool recurrent neural network and all that kind superstuff.\n",
    "\n",
    "But even without parallel corpora this system can be good enough (hopefully), in particular for similar languages, e.g. Ukrainian and Russian. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "idSYq2GU7uew"
   },
   "source": [
    "### Frament of the Swadesh list for some slavic languages\n",
    "\n",
    "The Swadesh list is a lexicostatistical stuff. It's named after American linguist Morris Swadesh and contains basic lexis. This list are used to define subgroupings of languages, its relatedness.\n",
    "\n",
    "So we can see some kind of word invariance for different Slavic languages.\n",
    "\n",
    "\n",
    "| Russian         | Belorussian              | Ukrainian               | Polish             | Czech                         | Bulgarian            |\n",
    "|-----------------|--------------------------|-------------------------|--------------------|-------------------------------|-----------------------|\n",
    "| женщина         | жанчына, кабета, баба    | жінка                   | kobieta            | žena                          | жена                  |\n",
    "| мужчина         | мужчына                  | чоловік, мужчина        | mężczyzna          | muž                           | мъж                   |\n",
    "| человек         | чалавек                  | людина, чоловік         | człowiek           | člověk                        | човек                 |\n",
    "| ребёнок, дитя   | дзіця, дзіцёнак, немаўля | дитина, дитя            | dziecko            | dítě                          | дете                  |\n",
    "| жена            | жонка                    | дружина, жінка          | żona               | žena, manželka, choť          | съпруга, жена         |\n",
    "| муж             | муж, гаспадар            | чоловiк, муж            | mąż                | muž, manžel, choť             | съпруг, мъж           |\n",
    "| мать, мама      | маці, матка              | мати, матір, неня, мама | matka              | matka, máma, 'стар.' mateř    | майка                 |\n",
    "| отец, тятя      | бацька, тата             | батько, тато, татусь    | ojciec             | otec                          | баща, татко           |\n",
    "| много           | шмат, багата             | багато                  | wiele              | mnoho, hodně                  | много                 |\n",
    "| несколько       | некалькі, колькі         | декілька, кілька        | kilka              | několik, pár, trocha          | няколко               |\n",
    "| другой, иной    | іншы                     | інший                   | inny               | druhý, jiný                   | друг                  |\n",
    "| зверь, животное | жывёла, звер, істота     | тварина, звір           | zwierzę            | zvíře                         | животно               |\n",
    "| рыба            | рыба                     | риба                    | ryba               | ryba                          | риба                  |\n",
    "| птица           | птушка                   | птах, птиця             | ptak               | pták                          | птица                 |\n",
    "| собака, пёс     | сабака                   | собака, пес             | pies               | pes                           | куче, пес             |\n",
    "| вошь            | вош                      | воша                    | wesz               | veš                           | въшка                 |\n",
    "| змея, гад       | змяя                     | змія, гад               | wąż                | had                           | змия                  |\n",
    "| червь, червяк   | чарвяк                   | хробак, черв'як         | robak              | červ                          | червей                |\n",
    "| дерево          | дрэва                    | дерево                  | drzewo             | strom, dřevo                  | дърво                 |\n",
    "| лес             | лес                      | ліс                     | las                | les                           | гора, лес             |\n",
    "| палка           | кій, палка               | палиця                  | patyk, pręt, pałka | hůl, klacek, prut, kůl, pálka | палка, пръчка, бастун |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNM3_fjr7ue2"
   },
   "source": [
    "But the context distribution of these languages demonstrates even more invariance. And we can use this fact for our for our purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YLppwa527ue6"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T04:14:54.286636Z",
     "start_time": "2021-04-13T04:14:52.824933Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "lYBGKAUn7ue_"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwGoVhRA7ufP"
   },
   "source": [
    "In this notebook we're going to use pretrained word vectors - FastText (original paper - https://arxiv.org/abs/1607.04606).\n",
    "\n",
    "You can download them from the official [website](https://fasttext.cc/docs/en/crawl-vectors.html). We're going to need embeddings for Russian and Ukrainian languages. Please use word2vec-compatible format (.text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T05:48:21.998244Z",
     "start_time": "2021-04-13T05:44:14.507909Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "u1JjQv_97ufT"
   },
   "outputs": [],
   "source": [
    "uk_emb = KeyedVectors.load_word2vec_format(\"cc.uk.300.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T05:52:21.203480Z",
     "start_time": "2021-04-13T05:48:21.999989Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ffzuept_7ufd"
   },
   "outputs": [],
   "source": [
    "ru_emb = KeyedVectors.load_word2vec_format(\"cc.ru.300.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T05:52:29.928915Z",
     "start_time": "2021-04-13T05:52:23.836986Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "nTkXfT0W7ufk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('август', 1.0),\n",
       " ('июль', 0.9383153915405273),\n",
       " ('сентябрь', 0.9240028858184814),\n",
       " ('июнь', 0.9222575426101685),\n",
       " ('октябрь', 0.9095538854598999),\n",
       " ('ноябрь', 0.8930036425590515),\n",
       " ('апрель', 0.8729087114334106),\n",
       " ('декабрь', 0.8652557730674744),\n",
       " ('март', 0.8545796275138855),\n",
       " ('февраль', 0.8401416540145874)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([ru_emb[\"август\"]], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T05:52:43.793787Z",
     "start_time": "2021-04-13T05:52:37.138162Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "vdBA8lcg7ufs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('серпень', 0.9999999403953552),\n",
       " ('липень', 0.9096440076828003),\n",
       " ('вересень', 0.901697039604187),\n",
       " ('червень', 0.8992519378662109),\n",
       " ('жовтень', 0.8810408711433411),\n",
       " ('листопад', 0.8787633776664734),\n",
       " ('квітень', 0.8592804670333862),\n",
       " ('грудень', 0.8586863279342651),\n",
       " ('травень', 0.8408110737800598),\n",
       " ('лютий', 0.8256431818008423)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_emb.most_similar([uk_emb[\"серпень\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T05:52:46.774119Z",
     "start_time": "2021-04-13T05:52:46.513285Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_yJvcKXO7uf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Stepashka.com', 0.2757962942123413),\n",
       " ('ЖИЗНИВадим', 0.25203436613082886),\n",
       " ('2Дмитрий', 0.25048112869262695),\n",
       " ('2012Дмитрий', 0.24829231202602386),\n",
       " ('Ведущий-Алексей', 0.2443869560956955),\n",
       " ('Недопустимость', 0.24435284733772278),\n",
       " ('2Михаил', 0.23981399834156036),\n",
       " ('лексей', 0.23740756511688232),\n",
       " ('комплексн', 0.23695150017738342),\n",
       " ('персональ', 0.2368222028017044)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([uk_emb[\"серпень\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNdYAR1q7uf6"
   },
   "source": [
    "Load small dictionaries for correspoinding words pairs as trainset and testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T05:52:57.552544Z",
     "start_time": "2021-04-13T05:52:57.547520Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "35d_DAK67uf8"
   },
   "outputs": [],
   "source": [
    "def load_word_pairs(filename):\n",
    "    uk_ru_pairs = []\n",
    "    uk_vectors = []\n",
    "    ru_vectors = []\n",
    "    with open(filename, \"r\") as inpf:\n",
    "        for line in inpf:\n",
    "            uk, ru = line.rstrip().split(\"\\t\")\n",
    "            if uk not in uk_emb or ru not in ru_emb:\n",
    "                continue\n",
    "            uk_ru_pairs.append((uk, ru))\n",
    "            uk_vectors.append(uk_emb[uk])\n",
    "            ru_vectors.append(ru_emb[ru])\n",
    "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T05:53:01.841286Z",
     "start_time": "2021-04-13T05:52:59.962324Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wkNL602WHJyO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-13 10:53:00--  http://tiny.cc/jfgecz\n",
      "Распознаётся tiny.cc (tiny.cc)… 157.245.113.153\n",
      "Подключение к tiny.cc (tiny.cc)|157.245.113.153|:80... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 301 Moved Permanently\n",
      "Адрес: https://tiny.cc/jfgecz [переход]\n",
      "--2021-04-13 10:53:00--  https://tiny.cc/jfgecz\n",
      "Подключение к tiny.cc (tiny.cc)|157.245.113.153|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 303 See Other\n",
      "Адрес: https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.train.txt [переход]\n",
      "--2021-04-13 10:53:01--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.train.txt\n",
      "Распознаётся raw.githubusercontent.com (raw.githubusercontent.com)… 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Подключение к raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 59351 (58K) [text/plain]\n",
      "Сохранение в: «ukr_rus.train.txt»\n",
      "\n",
      "ukr_rus.train.txt   100%[===================>]  57,96K  --.-KB/s    за 0,07s   \n",
      "\n",
      "2021-04-13 10:53:01 (858 KB/s) - «ukr_rus.train.txt» сохранён [59351/59351]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O ukr_rus.train.txt http://tiny.cc/jfgecz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T05:53:06.415225Z",
     "start_time": "2021-04-13T05:53:04.881087Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uoclU6JcHCcn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-13 10:53:04--  http://tiny.cc/6zoeez\n",
      "Распознаётся tiny.cc (tiny.cc)… 157.245.113.153\n",
      "Подключение к tiny.cc (tiny.cc)|157.245.113.153|:80... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 301 Moved Permanently\n",
      "Адрес: https://tiny.cc/6zoeez [переход]\n",
      "--2021-04-13 10:53:05--  https://tiny.cc/6zoeez\n",
      "Подключение к tiny.cc (tiny.cc)|157.245.113.153|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 303 See Other\n",
      "Адрес: https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.test.txt [переход]\n",
      "--2021-04-13 10:53:05--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.test.txt\n",
      "Распознаётся raw.githubusercontent.com (raw.githubusercontent.com)… 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Подключение к raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 12188 (12K) [text/plain]\n",
      "Сохранение в: «ukr_rus.test.txt»\n",
      "\n",
      "ukr_rus.test.txt    100%[===================>]  11,90K  --.-KB/s    за 0,001s  \n",
      "\n",
      "2021-04-13 10:53:06 (12,6 MB/s) - «ukr_rus.test.txt» сохранён [12188/12188]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O ukr_rus.test.txt http://tiny.cc/6zoeez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T05:53:10.746718Z",
     "start_time": "2021-04-13T05:53:10.713816Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "05BqsdSK7ugD"
   },
   "outputs": [],
   "source": [
    "uk_ru_train, X_train, Y_train = load_word_pairs(\"ukr_rus.train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T05:53:12.055970Z",
     "start_time": "2021-04-13T05:53:12.046236Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zQOZw51r7ugL"
   },
   "outputs": [],
   "source": [
    "uk_ru_test, X_test, Y_test = load_word_pairs(\"ukr_rus.test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ZBBNvpz7ugQ"
   },
   "source": [
    "## Embedding space mapping (0.3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_Dhk5gL7ugS"
   },
   "source": [
    "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called Procrustes problem:\n",
    "\n",
    "$$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$$\n",
    "or\n",
    "$$W^*= \\arg\\min_W ||WX - Y||_F$$\n",
    "\n",
    "where $||*||_F$ - Frobenius norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "acOjDdtL7ugY"
   },
   "source": [
    "$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$ looks like simple multiple linear regression (without intercept fit). So let's code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T06:10:50.077364Z",
     "start_time": "2021-04-13T06:10:49.998316Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Lb-KN1be7uga"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(fit_intercept=False, n_jobs=4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "mapping = LinearRegression(fit_intercept=False, n_jobs=4)\n",
    "mapping.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# mapping = ...\n",
    "# -------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X7tqJwoY7ugf"
   },
   "source": [
    "Let's take a look at neigbours of the vector of word _\"серпень\"_ (_\"август\"_ in Russian) after linear transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T06:29:18.344667Z",
     "start_time": "2021-04-13T06:29:18.214611Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "31SrFSbn7ugi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('апрель', 0.8531432747840881),\n",
       " ('июнь', 0.8402522802352905),\n",
       " ('март', 0.8385883569717407),\n",
       " ('сентябрь', 0.8331484198570251),\n",
       " ('февраль', 0.8311207890510559),\n",
       " ('октябрь', 0.8278018832206726),\n",
       " ('ноябрь', 0.8243728280067444),\n",
       " ('июль', 0.822961688041687),\n",
       " ('август', 0.8112279176712036)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
    "ru_emb.most_similar(august, topn=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "okSkjk597ugo"
   },
   "source": [
    "We can see that neighbourhood of this embedding cosists of different months, but right variant is on the ninth place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2uY6Y9B7ugt"
   },
   "source": [
    "As quality measure we will use precision top-1, top-5 and top-10 (for each transformed Ukrainian embedding we count how many right target pairs are found in top N nearest neighbours in Russian embedding space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T06:39:05.517998Z",
     "start_time": "2021-04-13T06:39:05.513860Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zptuho8LAfIE"
   },
   "outputs": [],
   "source": [
    "def precision(pairs, mapped_vectors, topn=1):\n",
    "    \"\"\"\n",
    "    :args:\n",
    "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
    "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
    "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
    "    :returns:\n",
    "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
    "    \"\"\"\n",
    "    assert len(pairs) == len(mapped_vectors)\n",
    "    num_matches = 0\n",
    "    for i, (_, ru) in enumerate(pairs):\n",
    "        ru_top = ru_emb.most_similar(mapped_vectors[i].reshape(1,300), topn=topn)\n",
    "        for (ru_translation, _) in ru_top:\n",
    "            if ru == ru_translation:\n",
    "                num_matches += 1\n",
    "    precision_val = num_matches / len(pairs)\n",
    "    return precision_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T06:39:07.401760Z",
     "start_time": "2021-04-13T06:39:07.015664Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "duhj9hpv7ugy"
   },
   "outputs": [],
   "source": [
    "assert precision([(\"серпень\", \"август\")], [august], topn=5) == 0.0\n",
    "assert precision([(\"серпень\", \"август\")], [august], topn=9) == 1.0\n",
    "assert precision([(\"серпень\", \"август\")], [august], topn=10) == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T06:40:29.159220Z",
     "start_time": "2021-04-13T06:39:08.880091Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "0-iyd5gP7ug5"
   },
   "outputs": [],
   "source": [
    "assert precision(uk_ru_test, X_test) == 0.0\n",
    "assert precision(uk_ru_test, Y_test) == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T06:57:37.239896Z",
     "start_time": "2021-04-13T06:56:09.803360Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "U-ssEJ3x7uhA"
   },
   "outputs": [],
   "source": [
    "precision_top1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
    "precision_top5 = precision(uk_ru_test, mapping.predict(X_test), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T06:57:37.245426Z",
     "start_time": "2021-04-13T06:57:37.242367Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7K-hy7a6Ksn2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.628498727735369\n",
      "0.7913486005089059\n"
     ]
    }
   ],
   "source": [
    "print(precision_top1)\n",
    "print(precision_top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hf6Ou8bx7uhH"
   },
   "source": [
    "## Making it better (orthogonal Procrustean problem) (0.3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4oLs-drN7uhK"
   },
   "source": [
    "It can be shown (see original paper) that a self-consistent linear mapping between semantic spaces should be orthogonal. \n",
    "We can restrict transform $W$ to be orthogonal. Then we will solve next problem:\n",
    "\n",
    "$$W^*= \\arg\\min_W ||WX - Y||_F \\text{, where: } W^TW = I$$\n",
    "\n",
    "$$I \\text{- identity matrix}$$\n",
    "\n",
    "Instead of making yet another regression problem we can find optimal orthogonal transformation using singular value decomposition. It turns out that optimal transformation $W^*$ can be expressed via SVD components:\n",
    "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
    "$$W^*=UV^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T06:57:37.252471Z",
     "start_time": "2021-04-13T06:57:37.249118Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_KSaRJFGMFiJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T06:59:46.970358Z",
     "start_time": "2021-04-13T06:59:46.967304Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "DdFQ7qti7uhL"
   },
   "outputs": [],
   "source": [
    "def learn_transform(X_train, Y_train):\n",
    "    \"\"\" \n",
    "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
    "    \"\"\"\n",
    "    A = X_train.T @ Y_train\n",
    "    U, S, V = np.linalg.svd(A)\n",
    "    mapping = U @ V\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T06:59:47.797580Z",
     "start_time": "2021-04-13T06:59:47.772219Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7X7QfYDd7uhQ"
   },
   "outputs": [],
   "source": [
    "W = learn_transform(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T06:59:48.632825Z",
     "start_time": "2021-04-13T06:59:48.508094Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "OVOFYYa37uhX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('апрель', 0.8245131969451904),\n",
       " ('июнь', 0.805662989616394),\n",
       " ('сентябрь', 0.8055762052536011),\n",
       " ('март', 0.8032934665679932),\n",
       " ('октябрь', 0.7987102270126343),\n",
       " ('июль', 0.7946797609329224),\n",
       " ('ноябрь', 0.7939636707305908),\n",
       " ('август', 0.7938189506530762),\n",
       " ('февраль', 0.7923860549926758),\n",
       " ('декабрь', 0.7715376615524292)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([np.matmul(uk_emb[\"серпень\"], W)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T07:01:24.370162Z",
     "start_time": "2021-04-13T06:59:57.452719Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "r297sYP37uhb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6437659033078881\n",
      "0.7989821882951654\n"
     ]
    }
   ],
   "source": [
    "print(precision(uk_ru_test, np.matmul(X_test, W)))\n",
    "print(precision(uk_ru_test, np.matmul(X_test, W), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvUZ72U5AfJg"
   },
   "source": [
    "## Unsupervised embedding-based MT (0.4 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLyuVfHBLrJn"
   },
   "source": [
    "Now, let's build our word embeddings-based translator!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tPAURW1CMuP7"
   },
   "source": [
    "Firstly, download OPUS Tatoeba corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T07:02:33.573077Z",
     "start_time": "2021-04-13T07:01:35.746093Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "F80kUKzQMsDu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-13 12:01:35--  https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/mono/uk.txt.gz\n",
      "Распознаётся object.pouta.csc.fi (object.pouta.csc.fi)… 86.50.254.18, 86.50.254.19\n",
      "Подключение к object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 1819128 (1,7M) [application/gzip]\n",
      "Сохранение в: «uk.txt.gz»\n",
      "\n",
      "uk.txt.gz           100%[===================>]   1,73M   218KB/s    за 40s     \n",
      "\n",
      "2021-04-13 12:02:33 (44,0 KB/s) - «uk.txt.gz» сохранён [1819128/1819128]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/mono/uk.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T07:02:44.540073Z",
     "start_time": "2021-04-13T07:02:44.379083Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "0CGFZoxCUVf1"
   },
   "outputs": [],
   "source": [
    "!gzip -d ./uk.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T07:02:45.449294Z",
     "start_time": "2021-04-13T07:02:45.398868Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "2MV3VvoVUX5U"
   },
   "outputs": [],
   "source": [
    "with open('./uk.txt', 'r') as f:\n",
    "    uk_corpus = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T07:02:46.432397Z",
     "start_time": "2021-04-13T07:02:46.423154Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tU7nPVf0UhbI"
   },
   "outputs": [],
   "source": [
    "# To save your time and CPU, feel free to use first 1000 sentences of the corpus\n",
    "uk_corpus = uk_corpus[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T07:03:45.825004Z",
     "start_time": "2021-04-13T07:03:45.819724Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "FLN8dBOXAfJ1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Я вже закінчу коледж, коли ви вернетеся з Америки.\\n'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Any necessary preprocessing if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T07:14:41.965489Z",
     "start_time": "2021-04-13T07:14:41.961387Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "FGksC7l_NMi9"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    \"\"\"\n",
    "    :args:\n",
    "        sentence - sentence in Ukrainian (str)\n",
    "    :returns:\n",
    "        translation - sentence in Russian (str)\n",
    "\n",
    "    * find ukrainian embedding for each word in sentence\n",
    "    * transform ukrainian embedding vector\n",
    "    * find nearest russian word and replace\n",
    "    \"\"\"\n",
    "    uk_words = sentence.split()\n",
    "    translated = []\n",
    "    NONE_WORD = '¯\\_(ツ)_/¯'\n",
    "    for word in uk_words:\n",
    "        if word not in uk_emb:\n",
    "            translated.append(NONE_WORD)\n",
    "            continue\n",
    "        ru_vec = uk_emb[word] @ W\n",
    "        ru_word = ru_emb.most_similar(ru_vec.reshape(1,300), topn=1)[0][0]\n",
    "        translated.append(ru_word)\n",
    "    return \" \".join(translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T07:14:43.723833Z",
     "start_time": "2021-04-13T07:14:43.008786Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "4hbbMy-tNxlf"
   },
   "outputs": [],
   "source": [
    "assert translate(\".\") == \".\"\n",
    "assert translate(\"1 , 3\") == \"1 , 3\"\n",
    "assert translate(\"кіт зловив мишу\") == \"кот поймал мышку\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ia6I2ce7O_HI"
   },
   "source": [
    "Now you can play with your model and try to get as accurate translations as possible. **Note**: one big issue is out-of-vocabulary words. Try to think of various ways of handling it (you can start with translating each of them to a special **UNK** token and then move to more sophisticated approaches). Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T07:15:30.541458Z",
     "start_time": "2021-04-13T07:14:44.666633Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ap1W7ZCeOAVU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я уже закончу ¯\\_(ツ)_/¯ когда мы прибежишь со океании\n",
      "Город бомбили враждебные ¯\\_(ツ)_/¯\n",
      "¯\\_(ツ)_/¯ мной ¯\\_(ツ)_/¯ конечно это не ¯\\_(ツ)_/¯ что мной не общаюсь со людьми\n",
      "Впрочем утра выпала ¯\\_(ツ)_/¯\n",
      "Беда не приходит одна\n",
      "Посмотри по тот жеребей\n",
      "Я заказал два ¯\\_(ツ)_/¯\n",
      "Я не хотел никого ¯\\_(ツ)_/¯\n",
      "Гора покрыта ¯\\_(ツ)_/¯\n",
      "по фотографии во девушки корона не со ¯\\_(ツ)_/¯ а со цветы\n",
      "Во меня То ¯\\_(ツ)_/¯\n",
      "Я приехал во Японию со Китая\n",
      "по север находится ¯\\_(ツ)_/¯ по юге — ¯\\_(ツ)_/¯ по востоке — ¯\\_(ツ)_/¯ и ещe дальше по востоке — северная ¯\\_(ツ)_/¯\n",
      "Его родная страна — ¯\\_(ツ)_/¯\n",
      "Берн — столица ¯\\_(ツ)_/¯\n",
      "Он ждал по него к десятой часа\n",
      "Ты можешь взять ту книгу ¯\\_(ツ)_/¯\n",
      "Такой роман сочинил известный американский писатель\n",
      "¯\\_(ツ)_/¯ будте ¯\\_(ツ)_/¯ комнату возле международного аэропорта во ¯\\_(ツ)_/¯\n",
      "Он ¯\\_(ツ)_/¯ что ты его ¯\\_(ツ)_/¯\n",
      "Я ¯\\_(ツ)_/¯ что ты ¯\\_(ツ)_/¯\n",
      "¯\\_(ツ)_/¯ кто всё ¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯\n",
      "Во этой реке опасно ¯\\_(ツ)_/¯\n",
      "¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯\n",
      "Я хожу к школы ¯\\_(ツ)_/¯\n",
      "Не моя ¯\\_(ツ)_/¯\n",
      "Не забудь ¯\\_(ツ)_/¯\n",
      "Кто ¯\\_(ツ)_/¯\n",
      "Вы будете чай ли ¯\\_(ツ)_/¯\n",
      "Он не пойдет по ¯\\_(ツ)_/¯ как и мной\n",
      "Когда Вы ¯\\_(ツ)_/¯\n",
      "Это моя любимая песня\n",
      "мы почти ¯\\_(ツ)_/¯\n",
      "Какой красивый сегодня ¯\\_(ツ)_/¯\n",
      "Я против каких-либо ¯\\_(ツ)_/¯\n",
      "поверхность воздушной шары — ¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯ потому для неё не выполняются правила симметрической ¯\\_(ツ)_/¯\n",
      "¯\\_(ツ)_/¯ что американцы считают количество ¯\\_(ツ)_/¯ какую зарабатывает ¯\\_(ツ)_/¯ мерилом его ¯\\_(ツ)_/¯\n",
      "Можно мной ¯\\_(ツ)_/¯ это ¯\\_(ツ)_/¯\n",
      "Если будет красивая ¯\\_(ツ)_/¯ мы доберёмся туда завтра\n",
      "Это был злой ¯\\_(ツ)_/¯\n",
      "¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯\n",
      "Кто во любви не ¯\\_(ツ)_/¯ тот горя не знает.И\n",
      "Его иметь волнуется за него\n",
      "Я уважаю ¯\\_(ツ)_/¯ кто старается со всех сил.И\n",
      "необычайная дружба переросла во глубокое чувство.\n",
      "Рейчел ¯\\_(ツ)_/¯ много молока каждый день\n",
      "Он ¯\\_(ツ)_/¯\n",
      "¯\\_(ツ)_/¯ загрязнение можно было бы ¯\\_(ツ)_/¯ только если бы люди были более чувствительны к окружающей среды\n",
      "чай со ¯\\_(ツ)_/¯ будте ¯\\_(ツ)_/¯\n",
      "Не путать желание со ¯\\_(ツ)_/¯\n",
      "Я бы со удовольствием сочинил сотни сложноподчинённые во ¯\\_(ツ)_/¯ конечно во меня То дела\n",
      "Дайте мне чашечку ¯\\_(ツ)_/¯\n",
      "ведь же ты никогда мне о это не ¯\\_(ツ)_/¯\n",
      "Во тебя будут ¯\\_(ツ)_/¯ если твои родители ¯\\_(ツ)_/¯\n",
      "Запах роз наполнил ¯\\_(ツ)_/¯\n",
      "Как во тебя ¯\\_(ツ)_/¯\n",
      "Это мои ¯\\_(ツ)_/¯\n",
      "¯\\_(ツ)_/¯ спасибо\n",
      "Я не ¯\\_(ツ)_/¯ почему Германия победила по ¯\\_(ツ)_/¯\n",
      "Добрый вечер\n",
      "Со ¯\\_(ツ)_/¯ Алексея Палашка поприветствовал президент Белоруссии Александр ¯\\_(ツ)_/¯\n",
      "Млечный путь — широкий пояс со далеких ¯\\_(ツ)_/¯ каждая звезда — ¯\\_(ツ)_/¯ такое как ¯\\_(ツ)_/¯\n",
      "удивительно видеть рок-звёзд со ¯\\_(ツ)_/¯\n",
      "всё печенье во форме ¯\\_(ツ)_/¯\n",
      "ЧТо мне одеть — штаны ли ¯\\_(ツ)_/¯\n",
      "Краусс утверждал — известный московский ¯\\_(ツ)_/¯\n",
      "Ой был злой ¯\\_(ツ)_/¯\n",
      "Можешь взять ¯\\_(ツ)_/¯ что тебе к ¯\\_(ツ)_/¯\n",
      "Конечно мной ¯\\_(ツ)_/¯\n",
      "шелковичные прядут ¯\\_(ツ)_/¯\n",
      "ЧТо бы ты ¯\\_(ツ)_/¯ если бы во тебя ¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯ десять тысяч ¯\\_(ツ)_/¯\n",
      "Он ¯\\_(ツ)_/¯ что он ¯\\_(ツ)_/¯ а действительно он никто\n",
      "она очень гордится своею коллекцией ¯\\_(ツ)_/¯\n",
      "Он очень ¯\\_(ツ)_/¯\n",
      "Какая ты ¯\\_(ツ)_/¯\n",
      "Как мной за тобой ¯\\_(ツ)_/¯\n",
      "Это ¯\\_(ツ)_/¯ что мной знаю\n",
      "Ты ведёшь ¯\\_(ツ)_/¯\n",
      "Тебе ¯\\_(ツ)_/¯\n",
      "Это ¯\\_(ツ)_/¯ а то — экспортно-импортный\n",
      "Это ¯\\_(ツ)_/¯ что мной хочу сделать.Но\n",
      "Я впервые смотрю такой страшный фильм\n",
      "Этa песня напоминает мне о домИ\n",
      "Хироси ¯\\_(ツ)_/¯\n",
      "Меня зовут ¯\\_(ツ)_/¯\n",
      "Как женщина ¯\\_(ツ)_/¯ так она и ¯\\_(ツ)_/¯\n",
      "Я здесь уже две часа\n",
      "Мне надо извиниться перед ¯\\_(ツ)_/¯\n",
      "Сегодня мной видел ¯\\_(ツ)_/¯\n",
      "¯\\_(ツ)_/¯ стоить та носовая ¯\\_(ツ)_/¯ — ¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯\n",
      "солдаты ¯\\_(ツ)_/¯ как ¯\\_(ツ)_/¯ очень ¯\\_(ツ)_/¯\n",
      "Он быстро ¯\\_(ツ)_/¯\n",
      "остальные ¯\\_(ツ)_/¯\n",
      "Он скучает по своей ¯\\_(ツ)_/¯\n",
      "¯\\_(ツ)_/¯ — ¯\\_(ツ)_/¯ ¯\\_(ツ)_/¯\n",
      "Я ещe не знаю своего ¯\\_(ツ)_/¯ мной определенный момент буду жить во ¯\\_(ツ)_/¯\n",
      "¯\\_(ツ)_/¯ вторая по длине река во мире после ¯\\_(ツ)_/¯\n",
      "А если увидишь ¯\\_(ツ)_/¯ передай ему от меня ¯\\_(ツ)_/¯\n",
      "закрой за собой дверь\n",
      "Держи при себе словар\n"
     ]
    }
   ],
   "source": [
    "for sent in uk_corpus[::10]:\n",
    "    print(translate(sent))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
